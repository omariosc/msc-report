\section{Introduction}

% \textbf{Background:} In low-middle-income countries (LMICs), there is a critical need for skilled surgeons. Alternative training processes that include computer-assisted surgical skill evaluation are essential to address this gap. Leveraging surgical videos to derive insights into tool detection and tracking is a highly researched area. This study focuses on detecting and tracking surgical tools in a new proposed dataset, AI-ELT (Artificial Intelligence Enhanced Laparoscopic Training), aiming to develop a generalisable model applicable to non-in vivo contexts.
% \textbf{Objectives:} The primary objective is to produce and compare state-of-the-art (SOTA) generalisable tool detection models for laparoscopic videos in the new AI-ELT dataset. This will help inform us which models are best suited for future research in non-in-vivo laparoscopic datasets. The areas of interest are comparing anchor-based and anchor-free methods, varying sizes of models and number of layers and parameters, inference times, and training times.

\subsection{Minimally Invasive Surgery and Laparoscopy}

Minimally invasive surgery (MIS) represents a significant advancement in surgical techniques, characterized by the use of small incisions and specialized instruments to perform complex procedures with minimal damage to surrounding tissues. Laparoscopy, a subset of MIS, involves the insertion of a laparoscope—a long, thin tube with a high-intensity light and a high-resolution camera at the front—into the abdomen through a small incision. This allows surgeons to view and operate on the internal organs with greater precision. The reduced trauma to the patient, faster recovery times, and lower risk of complications make MIS an attractive option, particularly in resource-constrained environments where hospital stays and postoperative care can be expensive and logistically challenging. However, the successful implementation of MIS in low and middle-income countries (LMICs) is often hindered by the lack of skilled surgeons and the high cost of the required equipment.

% Laparoscopy is a preferable approach for many surgical procedures, as it reduces blood loss, trauma, infection rate, and increases the speed of recovery compared to open surgery \cite{hasan_detection_2021}

\subsubsection{Low and Middle-Income Countries}

There are clear and persistent inequalities in access to surgical care between high-income countries (HICs) and low and middle-income countries (LMICs). In LMICs, the shortage of skilled surgeons poses a significant challenge, contributing to an estimated 5 billion people lacking access to safe and affordable surgical care, according to the Lancet Commission on Global Surgery (LCoGS) \cite{mearaglobal2015}. The LCoGS further emphasizes the need for 143 million additional surgical procedures annually to bridge this gap \cite{mearaglobal2015}. Furthermore, the World Health Organization (WHO) has highlighted a global shortfall of 44.5 million health workers, with a considerable proportion of this deficit being in surgery and anesthesia \cite{worldhealthorganizationglobal2016}. This shortage of skilled surgeons in LMICs is a substantial barrier to improving surgical outcomes and reducing the burden of surgical diseases in these regions. Consequently, there is a pressing need for scalable, effective training solutions that can elevate the surgical capacity in LMICs, particularly through innovative approaches such as tool detection and tracking in laparoscopic surgery, which can aid in both training and assessment.

The lack of large-scale datasets hampers Artificial Intelligence (AI) implementation in this domain \cite{nwoye_cholectrack20_2023}. Current datasets mainly focus on in-vivo context, which limits the generalizability of models and research overall to surgical training in non-in-vivo settings such as in LMICs. As tools become more sophisticated and versatile, the need for precise and accurate tracking becomes increasingly essential in assessing surgical skill.

The Lancet Commission on Global Surgery in 2015 highlighted the urgent need for increased volume and quality of surgery as an indispensable component of global health1. It recognized that developing safe, essential, life-saving surgical care in LMICs has increased at a drastically lower rate than in developed nations and requires massive expansion, with an additional 143 million surgeries per annum needed to fill this gap. While foreign surgical teams on short-term visits occasionally bridge the shortage of surgeons, anesthesiologists, and obstetricians in LMICs, some studies suggest that the skill transfer for a positive impact may be overestimated2. Specialized surgical training programs can benefit from AI-driven intelligent systems providing automated, personalized feedback to trainees. The LEST program will aim at developing and integrating low-cost systems that can be easily adapted to resource-constraint settings that can be easily set up in training programs. An automated evaluation tool to speed up the training outcomes without compromising the quality will be devised to mitigate the shortage of skills in LMICs. It is known that there is a paucity of wellcurated databases3 representing the LMIC population establishing further hurdles in the creation and development of these technologies. Thus, the LEST program will also help to advance technology development in the surgical data science field by compiling a large high-quality dataset of surgical procedures from underrepresented populations that require immediate addressing.
% 1 JG Meara, 10.1016/j.surg.2015.02.009 2 NO Kolozsvari, 10.1007/s00464-011-1743-9 3 L Meier-Hein, 10.1016/j.media.2021.102306

The Lancet Commission on Global Surgery (LCGS) in 2015 highlighted the urgent need for increased volume and quality of surgery as an indispensable component of global health19. It has been estimated that 11\% of deaths in low- and middle-income countries (LMICs) are due to conditions treatable by surgery20. 80\% of these deaths are preventable as they are caused by the lack of surgeons, consisting of cases that require only general surgical emergencies such as surgical site infections or trauma. In addition, postoperative infections, pain, and long-term complications are significant consequences that need to be reduced. Studies suggest that early postoperative mortality rates are 1-4\% depending upon country and institution, with the highest in low-income countries21, which translates to nearly 8 million deaths annually. The LCGS recognized that developing safe, essential, lifesaving surgical care in LMICs has a drastically lower rate than in developed nations and requires massive expansion. An additional 143 million surgeries per annum are needed to fill this gap, with nearly 30 million (~21\%) involving abdominal and pelvic conditions. A global effort to scale-up training is required to prepare an additional 100,000 surgeons and address the shortfall of interventions. While foreign surgical teams from highincome countries (HICs) on short-term visits occasionally bridge the shortage of surgeons, anesthesiologists, and obstetricians in LMICs, studies suggest that the skill transfer for a positive impact may be overestimated22. Some significant challenges concerning such visits from HICs to the LMICs are 1) associated cost, 2) cultural barriers, 3) insufficient follow-up and lack of sustainability23. Thus, a self-sustainable and comprehensive training program at a low cost is desperately required for effective management of the challenges faced in LMICs.
% 19 JG Meara, 10.1016/j.surg.2015.02.009 20 M Shrime, 10.1016/S2214-109X(14)70384-5 21 B Eyob, 10.1016/j.ijsu.2019.07.036 22 NO Kolozsvari, 10.1007/s00464-011-1743-9 23 L Velin, 10.1136/bmjgh-2022-008791

\subsection{Surgical Skill}

Currently, five billion people lack access to quality surgical care, with a significant variation in surgeon skills leading to complications and avoidable harm for patients \url{https://ieeexplore.ieee.org/document/8354185}. Improving surgical training and feedback is critical to reducing these rates, and assessing operative skill is essential to this improvement. Traditional methods of skill assessment are manual, time-consuming, and subjective. The current standard for surgical performance assessment is to have an expert surgeon observe the operation in its entirety and provide feedback to the surgeon performing the surgery. The Global Operative Assessment of Laparo-scopic Skills (GOALS) rating system, is a validated rubric for grading surgeons on laparoscopic surgery performance. For each of the five assessment domains of GOALS-depth perception, bimanual dexterity, efficiency, and tissue handling, and autonomy, surgeons are rated on a scale of 1 to 5, from least to most technically proficient, totaling to a final score out of 25. In order for an automated system to measure and evaluate these domains from a video feed, it must be able to detect and track the surgical tools used in the procedure, giving us the motivation to develop a model that can accurately detect and track the position of surgical tools in laparoscopic videos, which would be similar to what could be expected in a deployed system.

% The authors discuss how pose estimation techniques using computer vision and artificial intelligence could provide insight into the development of expertise and surgical performance over a surgeon's career. These tools have the potential to provide feedback to trainee surgeons, investigate the aspects of skill linked to patient outcomes, and assist educators in determining if trainees meet competency thresholds. https://cardiothoracicsurgery.biomedcentral.com/articles/10.1186/s13019-024-02558-5#:~:text=This%20narrative%20review%20synthesises%20work,computer%20vision%20and%20artificial%20intelligence.

% Real-time detection of surgical tools in laparoscopic data plays a vital role in under-standing surgical procedures, evaluating the performance of trainees, facilitating learning,and ultimately supporting the autonomy of robotic systems. \cite{Loza2023DTx}

% It has been shown that an increase in laparoscopic training may be directly correlated to characteristics in the motion primitives of the tool tips15. Using data inferred from our expert example procedures and training exercises, we will infer actions and characteristics of the motion that may be used to identify an expert surgeon compared to the actions of a novice or trainee16.
% 15 G Retrossi, 10.1089/lap.2015.0069 16 D Jones, 10.1089/end.2017.0894

% Surgical quality and outcome improvements are essential to address the disproportionate burden of surgical morbidity and mortality in LMICs. It is well-established that most current skill assessments are subjective and thus prone to human bias24,25
% 24 G Paley, 10.1016/j.jsurg.2021.02.004 25 M Levin, 10.1016/j.jsurg.2019.06.011

\subsection{Surgical Tool Detection and Tracking}

% Methods for detecting and localizing surgical instruments in laparoscopic images are an important element of advanced robotic and computer-assisted interventions https://ieeexplore.ieee.org/abstract/document/6359786.
% Intraoperative segmentation and tracking of minimally invasive instruments is a prerequisite for computerand robotic-assisted surgery. https://arxiv.org/pdf/1805.02475

Tool tracking in surgical videos is vital in computer-assisted intervention for skill assessment during MIS \cite{nwoye_cholectrack20_2023}. The field of surgical tool detection and tracking has seen significant advancements with the advent of deep learning and computer vision technologies. Existing models such as RetinaNet, EfficientDet, YOLOv8, YOLOv10, ART-Net, and DTX have demonstrated varying degrees of success in detecting and tracking surgical instruments in real-time, which is crucial for applications in MIS. These models leverage sophisticated architectures, including convolutional neural networks (CNNs) and time-series analysis, to accurately identify and locate surgical tools within video frames. The anchor-based models, such as those built on the YOLO architecture, use predefined anchor boxes to predict bounding boxes, while anchor-free models like ART-Net predict the location of tools directly, potentially offering greater flexibility in varying surgical environments. The evaluation of these models is commonly performed using the Common Objects in Context (COCO) dataset's metrics, particularly the mean Average Precision (mAP) and Intersection over Union (IoU) scores, which provide a robust measure of the model's performance in detecting objects within a defined area. These advancements not only improve the precision of tool tracking in surgical videos but also enhance the potential for automated skill assessment in surgical training.

\subsection{Objectives}

The primary objective of this study is to develop a model that can accurately detect and track the position of surgical tools in laparoscopic videos, tailored for use in surgical training programs within LMICs. Given the resource constraints in these settings, the models need to be both computationally efficient and reliable. The goal is to provide real-time feedback to trainees, enabling a more effective evaluation of their surgical skills. By facilitating objective assessments of tool positioning and manipulation, these models can help bridge the training gap in regions where access to expert supervision is limited. Additionally, this study aims to compare the performance of different deep learning architectures—specifically anchor-based models, such as those using YOLOv10, and anchor-free models, such as ART-Net. The impact of various training strategies, including transfer learning and data augmentation, on the models' performance will also be explored. The findings from this comparative analysis will inform the development of more generalizable models applicable to a wide range of laparoscopic procedures, particularly in non-in vivo contexts.

\subsection{Contributions}

In this paper, we present a novel dataset of laparoscopic surgical videos and detail the development and validation of state-of-the-art (SOTA) deep learning-based models for surgical tool detection and tracking. The dataset comprises 24 videos, totaling 103,629 frames of a peg transfer task performed using fenestrated (Reddick) and curved (Maryland) forceps. Each frame is meticulously annotated with tooltips and ground truth values that include the tool's position in three dimensions and a quaternion representing its spatial orientation and rotation, providing six degrees of freedom (6DOF). To ensure robust model validation, we have manually labeled 1\% of the images across 23 videos, with one video fully labeled as a test set.

We propose two models for tracking surgical tools: an anchor-based deep learning model built on the YOLOv10 architecture, and a reimplementation of the anchor-free ART-Net model \cite{hasan_detection_2021}. Our evaluation shows that the YOLOv10 model achieved a mean Average Precision (mAP50) of 99.0\% and a mAP50-95 of 80.9\% on the test set, with an inference time of 25.4ms per frame. These results demonstrate the effectiveness of our models in accurately detecting and tracking surgical tools, even in the challenging environments typical of LMICs. The dataset and models we present have significant potential for application in laparoscopic surgical skill analysis and workflow recognition, contributing to the advancement of surgical training programs and ultimately improving surgical outcomes in resource-constrained settings.

% TABLE OF ACRONYMS
\begin{table}[h]
    \centering
    \caption{Table of Acronyms}
    \begin{tabular}{ll}
      \toprule
      \textbf{Acronym} & \textbf{Definition} \\
      \midrule
      6DOF & Six Degrees of Freedom \\
      AI & Artificial Intelligence \\
      COCO & Common Objects in Context \\
      FPS & Frames Per Second \\
      HICs & High-Income Countries \\
      IoU & Intersection over Union \\
      LCoGS & Lancet Commission on Global Surgery \\
      LMICs & Low and Middle-Income Countries \\
      MIS & Minimally Invasive Surgery \\
      mAP & Mean Average Precision \\
      SOTA & State-of-the-Art \\
      WHO & World Health Organization \\
      \bottomrule
    \end{tabular}
    \label{tab:acronyms}
  \end{table}
